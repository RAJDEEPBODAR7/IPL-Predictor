{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<marquee scrollamount=\"20\" direction=\"right\"><h1 align=\"center\">WINNING TEAM PREDICTOR</h1></marquee>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">------------ ORGANIZING DATASET ------------</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from colorama import Fore\n",
    "pd.options.mode.chained_assignment = None  # otherwise gives unncessary warning for direct indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    delivery=pd.read_csv(\"deliveries.csv\")\n",
    "    matches=pd.read_csv(\"matches.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(Fore.RED+\"Dataset Not Found!\"+Fore.RESET)\n",
    "else:\n",
    "    print(Fore.GREEN+\"Dataset Loaded Successfully\"+Fore.BLACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the dataset and analyzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.shape  # no. of rows and no. of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby(\"Season\")[\"Season\"].count() # tells no. of matches played in every season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby(\"Season\")[\"Season\"].count().cumsum()  # cumulative sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deciding which columns to consider for final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.columns  # tells columns field --> we need to reduce it to make efficient in data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important paramter for data analysis -->  batting team --> A , bowling team --> B , runs left B , balls left B , wickets left B , total runs scored by A , current run rate B , required run rate B , city , match result A or B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total runs for each match in each inning\n",
    "total_runs_df=delivery.groupby([\"match_id\",\"inning\"])[\"total_runs\"].sum()\n",
    "total_runs_df=total_runs_df.reset_index()\n",
    "total_runs_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we require total runs of first team only\n",
    "total_runs_df = total_runs_df.query(\"inning==1\")\n",
    "# total_runs_df.shape  # --> same rows count as matches , hence merge possible\n",
    "total_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the total_runs scored by team1 with matches dataframe\n",
    "match_df = pd.merge(matches,total_runs_df[[\"match_id\",\"total_runs\"]],left_on='id',right_on='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now this dataframe contains id two time therefor removing match_id\n",
    "if(\"match_id\" in match_df.columns):\n",
    "    match_df = match_df.drop(columns=\"match_id\")\n",
    "    print(\"Dropped Successfully!\")\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now need to drop those teams who is not playing ipl currently\n",
    "# all teams \n",
    "# match_df.groupby(\"team1\")[\"team1\"].count()\n",
    "match_df[\"team1\"].unique()   # Gujarat Lions ,Rising Pune Supergiants ,Kochi Tuskers Kerala ,Pune Warriors --> no longer playing\n",
    "# Delhi Daredevils == Delhi Capitals\n",
    "# Deccan Chargers == Sunrisers Hyderabad --> we will change the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying team name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifing team name\n",
    "match_df[\"team1\"]=match_df[\"team1\"].str.replace(\"Delhi Daredevils\",\"Delhi Capitals\")\n",
    "match_df[\"team1\"]=match_df[\"team1\"].str.replace(\"Deccan Chargers\",\"Sunrisers Hyderabad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in team2\n",
    "match_df[\"team2\"]=match_df[\"team2\"].str.replace(\"Delhi Daredevils\",\"Delhi Capitals\")\n",
    "match_df[\"team2\"]=match_df[\"team2\"].str.replace(\"Deccan Chargers\",\"Sunrisers Hyderabad\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in toss winner\n",
    "match_df[\"toss_winner\"]=match_df[\"toss_winner\"].str.replace(\"Delhi Daredevils\",\"Delhi Capitals\")\n",
    "match_df[\"toss_winner\"]=match_df[\"toss_winner\"].str.replace(\"Deccan Chargers\",\"Sunrisers Hyderabad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in winner\n",
    "match_df[\"winner\"]=match_df[\"winner\"].str.replace(\"Delhi Daredevils\",\"Delhi Capitals\")\n",
    "match_df[\"winner\"]=match_df[\"winner\"].str.replace(\"Deccan Chargers\",\"Sunrisers Hyderabad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for delivery\n",
    "delivery[\"batting_team\"]=delivery[\"batting_team\"].str.replace(\"Delhi Daredevils\",\"Delhi Capitals\")\n",
    "delivery[\"batting_team\"]=delivery[\"batting_team\"].str.replace(\"Deccan Chargers\",\"Sunrisers Hyderabad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery[\"bowling_team\"]=delivery[\"bowling_team\"].str.replace(\"Delhi Daredevils\",\"Delhi Capitals\")\n",
    "delivery[\"bowling_team\"]=delivery[\"bowling_team\"].str.replace(\"Deccan Chargers\",\"Sunrisers Hyderabad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df[\"team1\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Only those teams which consistently playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_teams=[\"Royal Challengers Bangalore\",\"Kolkata Knight Riders\",\"Kings XI Punjab\",\"Sunrisers Hyderabad\"\n",
    "                   ,\"Mumbai Indians\",\"Delhi Capitals\",\"Chennai Super Kings\",\"Rajasthan Royals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df[(match_df[\"team1\"].isin(consistent_teams)) & (match_df[\"team2\"].isin(consistent_teams))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_df\n",
    "match_df.shape  # no. of matches reduced from 756 to 641"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing those matches where match remain suspended due to rain and duckworth-lewis applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df[\"dl_applied\"].value_counts()  # 15 matches were affected by rain --> hence removing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df[match_df[\"dl_applied\"]==0]  # removed 15 matches\n",
    "match_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Those Columns which are required from match_df DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id --> to join with delivery dataframe , city , winner , total_runs\n",
    "match_df = match_df[[\"id\",\"city\",\"winner\",\"total_runs\"]]\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merging match_df with delivery --> where id is same --> each match has unique id\n",
    "merge_df = pd.merge(delivery,match_df,left_on=\"match_id\",right_on=\"id\")\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now removing id as it contains 2 times\n",
    "if(\"id\" in merge_df.columns):\n",
    "    merge_df.drop(columns=\"id\",inplace=True)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here total_runs_y means target for 2nd team_x\n",
    "merge_df.rename(columns={\"total_runs_y\":\"target\"},inplace=True)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now incrementing target field by 1 as target is always +1 to runs scored by 1st team\n",
    "merge_df[\"target\"] = merge_df[\"target\"].apply(lambda x:x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to predict on basis of target by 1st team --> hence removing innnings = 1  (since we already obtained the target) and ball to ball delivery is not required\n",
    "merge_df = merge_df[merge_df[\"inning\"]==2]\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now calculating balls left , runs left and wickets left after each ball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>for balls left</u> --> 120 - ((over-1)*6 + ball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column --> balls faced\n",
    "merge_df[\"balls_faced\"] = (merge_df[\"over\"]-1)*6 +(merge_df[\"ball\"])\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column --> balls_left\n",
    "merge_df[\"balls_left\"] = 120 - merge_df[\"balls_faced\"]\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>for runs left</u> for each match --> first groupby by match_id and then find cumulative sum , then minus from target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column --> score\n",
    "merge_df[\"current_score\"] = merge_df.groupby(\"match_id\")[\"total_runs_x\"].cumsum()\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column --> runs_left\n",
    "merge_df[\"runs_left\"] = merge_df[\"target\"] - merge_df[\"current_score\"]\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>for wickets left</u> --> add 1 when player_dismissed == 1 and (10 - answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df[\"player_dismissed\"].fillna(0,inplace=True)\n",
    "merge_df[\"player_dismissed\"] = merge_df[\"player_dismissed\"].apply(lambda x:x if x==0 else 1)  # if not 0 then replace by 1 and 1 means wicket fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column --> wickets_fallen\n",
    "merge_df[\"wickets_fallen\"] = merge_df.groupby(\"match_id\")[\"player_dismissed\"].cumsum()\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column --> wickets_left\n",
    "merge_df[\"wickets_left\"] = 10 - merge_df[\"wickets_fallen\"]\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df.query(\"match_id==1\") --> to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating current run rate and required run rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRR --> (current_score) * 6 / (balls_faced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column --> CRR\n",
    "merge_df[\"CRR\"] = merge_df[\"current_score\"] * 6 / (merge_df[\"balls_faced\"])\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RRR -->  (runs_left * 6) / (balls_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new column --> RRR\n",
    "merge_df[\"RRR\"] = merge_df[\"runs_left\"] * 6 / (merge_df[\"balls_left\"])\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting result in terms of 0 and 1  --->  0 means team1 (first batting) won and 1 means team2 (chasing team) won , result will be compare on basis of chasing team "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df[\"batting_team\"].apply(lambda x:x if x==\"Royal Challengers Bangalore\" else 1) --> lambda takes 1D value . hence cannot use , instead use function\n",
    "def final_result(match):\n",
    "    if(match[\"batting_team\"]==match[\"winner\"]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "merge_df[\"result\"] = merge_df.apply(final_result,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df[\"batting_team\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW ALL THE INFORMATION IS COMPUTED AND ANALYZED , NOW RETRIEVING THOSE FIELDS ONLY WHICH ARE REQUIRED FOR CREATING PREDICTION MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batting team --> A , bowling team --> B , runs left B , balls left B , wickets left B , total runs scored by A , current run rate B , required run rate B , city , match result A or B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = merge_df[[\"match_id\",\"city\",\"batting_team\",\"bowling_team\",\n",
    "        \"target\",\"current_score\",\"runs_left\",\n",
    "        \"balls_faced\",\"balls_left\",\n",
    "        \"wickets_fallen\",\"wickets_left\",\n",
    "        \"CRR\",\"RRR\",\"result\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data.shape)\n",
    "final_data  # here result gives answer about whether the chasing team won or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking whether sum cells are empty\n",
    "final_data.isnull().sum()  # city contains null values --> removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.dropna()\n",
    "print(final_data.shape)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since rrr was becoming -inf or inf when balls_left becomes 0 , hence removing last ball --> it doesn't affects much on model\n",
    "final_data = final_data[final_data[\"balls_left\"] != 0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.reset_index()  #--> reseted the index \n",
    "final_data.drop(columns=[\"index\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.sample(frac=1)    # shuffling the dataframe so, the ml model can divide and result doesn't look baised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(\"final_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW BUILDING MODEL USING SKLEARN ( SCIKIT LEARN - MACHINE LEARNING LIBRARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the basis of runs, balls, wicket, city, battingteam , bowling team and target we are going to predict the winning ratio of both teams (result in percentage) --> result is dependent variable (response variable) and all other paramters are independent variables (predictor variable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Test Split : https://www.youtube.com/watch?v=fwY9Qv96DJY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"maxresdefault.jpg\" alt=\"traintestsplit\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# split the dataframe into training and testing phase\n",
    "# to train the model using training sample (80% mostly)  --> selects random sample\n",
    "# test the model using test sample\n",
    "\n",
    "# firstly dividing the independent and dependent variable in X and y on which testing and training required\n",
    " \n",
    "# X  --> independent varaiable\n",
    "X = final_data.iloc[:,1:-1]   # all atributes except last column\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y --> dependent variable\n",
    "y = final_data.iloc[:,-1]  # only last column (result)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2 , random_state=1)  # test size -> 20% and train size --> 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train    # here city , batting team and bowling team is in string hence need to use one hot encoding otherwise gives problem since ml models are good in managing numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Column Transformer : https://www.youtube.com/watch?v=5TVj6iEBR4I\n",
    "##### One Hot Encoding : https://www.youtube.com/watch?v=9yl6-HEY7_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"onehotencoding.png\" alt=\"ohe\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# differnet encoders --> SimpleImputer --> replaces null/NaN with mean values  , OneHotDecoder , OridinalEncoder\n",
    "# since here categorical data is in 3 columns so, need to use column transformer\n",
    "\n",
    "ohe = ColumnTransformer(transformers=[(\"trf\",OneHotEncoder(sparse=False,drop=\"first\"),[\"city\",\"batting_team\",\"bowling_team\"])],remainder=\"passthrough\")  # remainder --> drop or remain as it is (passthrough) the other columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelining and logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[(\"step1\",ohe),(\"step2\",LogisticRegression(solver=\"liblinear\"))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fit , transform , fit_transform , predict : https://www.youtube.com/watch?v=BotYLBQfd5M "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit --> it gives the required paramters for example in SimpleImputer --> Mean <br>\n",
    "transform --> it transforms the data based on fit value ,sets null/NaN value to mean in SimpleImputer<br>\n",
    "fit_transform --> combination of above 2 --> same as fit().transform()<br>\n",
    "**fit and transform for train data**<br>\n",
    "**transform for test data**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in model only 2 process  --> fit and predict <br>\n",
    "**fit for training data and predict for test data** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = pipe.predict(X_test)   # preedicts based on trained values\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We calculate accuracy by dividing the number of correct predictions (the corresponding diagonal in the matrix) by the total number of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(predict_y,y_test)\n",
    "print(\"Accuracy : {:.3f} %\".format(acc*100))  # can use other models too , but high accuracy doesn't mean it is suitable for our problem  --> since it doesn't give more flexibity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probability\n",
    "pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand = list(final_data[\"match_id\"])\n",
    "match_id = random.choice(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"final_df.pkl\",\"wb\") as f:\n",
    "    pickle.dump(final_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the probability after each over in particular match\n",
    "def match_prob(id,pipe):\n",
    "    data = final_data[final_data[\"match_id\"]==id]\n",
    "    xyz = final_data.query(f\"((balls_faced>=114 and balls_faced<=119) or balls_faced%6 ==0 ) and match_id == {id}\")\n",
    "    xyz.sort_values(\"balls_faced\",inplace=True)\n",
    "    wxy = xyz[xyz[\"balls_faced\"]%6==0]\n",
    "    wxy = wxy.append(xyz.iloc[-1])\n",
    "    data = wxy.iloc[:,1:-1]\n",
    "    result = pipe.predict_proba(data)\n",
    "    data[\"lose_prob\"] = np.round(result.T[0]*100,1)\n",
    "    data[\"win_prob\"] = np.round(result.T[1]*100,1)\n",
    "    target = data[\"target\"].values[0]\n",
    "    print(\"Target-\",target)\n",
    "    new = data[[\"current_score\",\"balls_faced\",\"wickets_fallen\",\"lose_prob\",\"win_prob\"]]\n",
    "    new['end_of_over'] = range(1,new.shape[0]+1)\n",
    "    new[\"runs_in_over\"] = new[\"current_score\"].diff()\n",
    "    over1 = new[\"current_score\"].values[0]\n",
    "    wicket1 = new[\"wickets_fallen\"].values[0]\n",
    "    new[\"runs_in_over\"] = new[\"runs_in_over\"].fillna(over1) \n",
    "    new[\"runs_in_over\"] = new[\"runs_in_over\"].astype(int)\n",
    "    new[\"wicket_in_over\"] = new[\"wickets_fallen\"].diff()\n",
    "    new[\"wicket_in_over\"] = new[\"wicket_in_over\"].fillna(wicket1)\n",
    "    new[\"wicket_in_over\"] = new[\"wicket_in_over\"].astype(int)\n",
    "    return new,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a , b = match_prob(69,pipe)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df,target = match_prob(1,pipe)\n",
    "new_df.reset_index(inplace=True)\n",
    "new_df.drop(columns=[\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiation \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(15,7))\n",
    "x_value = new_df['end_of_over']\n",
    "plt.plot(x_value,new_df['wicket_in_over'],color='yellow',lw=3,label=\"Fall of wicket\")\n",
    "plt.plot(x_value,new_df['win_prob'],color='#00a65a',lw=3,label=\"Winning Ratio\")\n",
    "plt.plot(x_value,new_df['lose_prob'],color='red',lw=3,label=\"Losing Ratio\")\n",
    "plt.bar(x_value,new_df['runs_in_over'])\n",
    "plt.xticks(np.arange(1,21))\n",
    "plt.yticks(np.arange(0,101,20))\n",
    "plt.title('Target-' + str(target))\n",
    "plt.xlabel(\"End Of The Over\")\n",
    "plt.ylabel(\"Probabilty\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_teams.sort()\n",
    "consistent_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = list(final_data[\"city\"].unique())\n",
    "city.sort()\n",
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Teams.pkl\",\"wb\") as f:\n",
    "    pickle.dump(consistent_teams,f)  # storing structure in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Cities.pkl\",\"wb\") as f:\n",
    "    pickle.dump(city,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pickle in Python is primarily used in serializing and deserializing a Python object structure. In other words, it's the process of converting a Python object into a byte stream to store it in a file/database, maintain program state across sessions, or transport data over the network.* <br>\n",
    "*\"Pickling\" is process which enables storage and preservation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dump --> to store object structure in some file in binary(bytes format) <br>\n",
    "load --> to load data from that file object in orginal data type object(list,dictionary,etc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"struct.pkl\",\"wb\") as f:\n",
    "    pickle.dump(pipe,f)   # takes 2 parameters --> object structure and file object"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebb7ca7dfbffd64145f110f03afc50e81fe37f2d5a4d159582d380dd9349a6e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
